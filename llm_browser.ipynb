{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "✅ Playwright browsers installed successfully\n"
          ]
        }
      ],
      "source": [
        "# # First, let's install the required dependencies\n",
        "# # Note: Installing TorchRL with LLM support and playwright\n",
        "\n",
        "# # Install TorchRL with LLM dependencies\n",
        "# %pip install \"torchrl[llm]\" --quiet\n",
        "\n",
        "# # Install playwright for browser automation\n",
        "# import subprocess\n",
        "# import sys\n",
        "\n",
        "# try:\n",
        "#     result = subprocess.run([sys.executable, \"-m\", \"playwright\", \"install\"], \n",
        "#                           capture_output=True, text=True, check=True)\n",
        "#     print(\"✅ Playwright browsers installed successfully\")\n",
        "# except subprocess.CalledProcessError as e:\n",
        "#     print(f\"❌ Error installing playwright browsers: {e}\")\n",
        "#     print(\"Stdout:\", e.stdout)\n",
        "#     print(\"Stderr:\", e.stderr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# TorchRL LLM: Building Tool-Enabled Environments\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "This tutorial demonstrates how to build and compose LLM environments with tool capabilities\n",
        "in TorchRL. We'll show how to create a complete environment that can execute tools,\n",
        "format responses, and handle interactions between the LLM and external tools.\n",
        "\n",
        "The tutorial uses web browsing as a concrete example, but the concepts apply to any\n",
        "tool integration in TorchRL's LLM framework.\n",
        "\n",
        "Main takeaways:\n",
        "\n",
        "- Understanding TorchRL's LLM environment composition\n",
        "- Creating and appending tool transforms\n",
        "- Formatting tool responses and LLM interactions\n",
        "- Handling tool execution and state management\n",
        "\n",
        "Prerequisites: Basic familiarity with TorchRL's environment concepts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "First, install TorchRL with LLM support. If you're running this in a Jupyter\n",
        "notebook, you can install the packages using:\n",
        "\n",
        "```bash\n",
        "%pip install \"torchrl[llm]\"    # Install TorchRL with all LLM dependencies\n",
        "```\n",
        "The `torchrl[llm]` package includes all necessary dependencies for LLM functionality,\n",
        "including transformers, vllm, and playwright for browser automation.\n",
        "\n",
        "After installation, you'll need to set up the browser automation components:\n",
        "\n",
        "```bash\n",
        "!playwright install            # Install browser binaries\n",
        "```\n",
        "Note: The `!` and `%pip` prefixes are specific to Jupyter notebooks. In a regular\n",
        "terminal, use these commands without the prefixes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "TorchRL's LLM interface is built around composable environments and transforms.\n",
        "The key components are:\n",
        "\n",
        "1. A base environment (ChatEnv)\n",
        "2. Tool execution transforms\n",
        "3. Data loading transforms\n",
        "4. Reward computation transforms\n",
        "\n",
        "Let's import the necessary components and set up our environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "\n",
        "from tensordict import set_list_to_stack, TensorDict\n",
        "from torchrl import torchrl_logger\n",
        "from torchrl.data import CompositeSpec, Unbounded\n",
        "from torchrl.envs import Transform\n",
        "from torchrl.envs.llm import ChatEnv\n",
        "from torchrl.envs.llm.transforms.browser import BrowserTransform\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Basic Environment Configuration\n",
        "\n",
        "We'll create a ChatEnv and configure it with browser automation capabilities.\n",
        "First, we enable list-to-stack conversion for TensorDict, which is required\n",
        "for proper batch handling in LLM environments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Enable list-to-stack conversion for TensorDict\n",
        "set_list_to_stack(True).set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll create the tokenizer and base environment. The environment requires\n",
        "a batch size, even if we're only running a single instance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
        "\n",
        "# Original code - this has an invalid parameter 'apply_template'\n",
        "# env = ChatEnv(\n",
        "#     batch_size=(1,),\n",
        "#     tokenizer=tokenizer,\n",
        "#     apply_template=True,\n",
        "#     system_prompt=(\n",
        "#         \"You are a helpful assistant that can use tools to accomplish tasks. \"\n",
        "#         \"Tools will be executed and their responses will be added to our conversation.\"\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "# Fixed code - removed 'apply_template' parameter which doesn't exist in ChatEnv\n",
        "env = ChatEnv(\n",
        "    batch_size=(1,),\n",
        "    tokenizer=tokenizer,\n",
        "    system_prompt=(\n",
        "        \"You are a helpful assistant that can use tools to accomplish tasks. \"\n",
        "        \"Tools will be executed and their responses will be added to our conversation.\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll add the browser transform with safety configurations. This transform\n",
        "enables web browsing capabilities with domain restrictions for security.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Original code that might have issues with the current TorchRL version\n",
        "browser_transform = BrowserTransform(\n",
        "    allowed_domains=[\"google.com\", \"github.com\"],\n",
        "    headless=False,  # Set to False to see the browser actions\n",
        ")\n",
        "env = env.append_transform(browser_transform)\n",
        "\n",
        "# Let's try a different approach - first check if BrowserTransform works differently\n",
        "# print(\"Checking BrowserTransform parameters...\")\n",
        "# try:\n",
        "#     # Let's see what parameters BrowserTransform actually expects\n",
        "#     import inspect\n",
        "#     browser_sig = inspect.signature(BrowserTransform.__init__)\n",
        "#     print(f\"BrowserTransform signature: {browser_sig}\")\n",
        "    \n",
        "#     # Try creating the transform with minimal parameters\n",
        "#     browser_transform = BrowserTransform()\n",
        "#     print(\"✅ BrowserTransform created successfully with default parameters\")\n",
        "    \n",
        "#     # Now try appending it\n",
        "#     env = env.append_transform(browser_transform)\n",
        "#     print(\"✅ BrowserTransform appended successfully\")\n",
        "    \n",
        "# except Exception as e:\n",
        "#     print(f\"❌ BrowserTransform creation failed: {e}\")\n",
        "#     print(\"Continuing without browser transform for now...\")\n",
        "#     browser_transform = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also design a transform to assign rewards to the environment.\n",
        "For example, we can parse the result of the browser transform to assign a reward\n",
        "whenever specific goals are achieved. Very simply, in this example, we will assign\n",
        "a reward of 2 if the LLM finds the answer to the question (Paris), a reward of 1 if it\n",
        "reaches the desired website, and a reward of 0 otherwise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class RewardTransform(Transform):\n",
        "    \"\"\"A transform that assigns rewards based on the LLM's responses.\n",
        "\n",
        "    This transform parses the browser responses in the environment's history and assigns\n",
        "    rewards based on specific achievements:\n",
        "\n",
        "    - Finding the correct answer (Paris): reward = 2.0\n",
        "    - Successfully reaching Google: reward = 1.0\n",
        "    - Otherwise: reward = 0.0\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def _call(self, tensordict: TensorDict) -> TensorDict:\n",
        "        \"\"\"Process the tensordict and assign rewards based on the LLM's response.\n",
        "\n",
        "        Args:\n",
        "            tensordict (TensorDict): The tensordict containing the environment state.\n",
        "                Must have a \"history\" key containing the conversation history.\n",
        "\n",
        "        Returns:\n",
        "            TensorDict: The tensordict with an added \"reward\" key containing the\n",
        "                computed reward with shape (B, 1) where B is the batch size.\n",
        "        \"\"\"\n",
        "        # ChatEnv has created a history item. We just pick up the last item,\n",
        "        # and check if `\"Paris\"` is in the response.\n",
        "        # We use index 0 because we are in a single-instance environment.\n",
        "        history = tensordict[\"history\"]\n",
        "        \n",
        "        # Check if history has prompt attribute and it's not None\n",
        "        if hasattr(history, 'prompt') and history.prompt is not None:\n",
        "            last_item = history.prompt[-1]\n",
        "            # Check if the last item has content attribute\n",
        "            if hasattr(last_item, 'content') and \"Paris\" in str(last_item.content):\n",
        "                torchrl_logger.info(\"Found the answer to the question: Paris\")\n",
        "                # Recall that rewards have a trailing singleton dimension.\n",
        "                tensordict[\"reward\"] = torch.full((1, 1), 2.0)\n",
        "            # Check if we successfully reached the website\n",
        "            elif (\n",
        "                hasattr(last_item, 'content') and \n",
        "                \"google.com\" in str(last_item.content) and\n",
        "                \"executed successfully\" in str(last_item.content)\n",
        "            ):\n",
        "                torchrl_logger.info(\"Reached the website google.com\")\n",
        "                tensordict[\"reward\"] = torch.full((1, 1), 1.0)\n",
        "            else:\n",
        "                tensordict[\"reward\"] = torch.full((1, 1), 0.0)\n",
        "        else:\n",
        "            # If no proper history available, give zero reward\n",
        "            tensordict[\"reward\"] = torch.full((1, 1), 0.0)\n",
        "        return tensordict\n",
        "\n",
        "    def transform_reward_spec(self, reward_spec: CompositeSpec) -> CompositeSpec:\n",
        "        \"\"\"Transform the reward spec to include our custom reward.\n",
        "\n",
        "        This method is required to override the reward spec since the environment\n",
        "        is initially reward-agnostic.\n",
        "\n",
        "        Args:\n",
        "            reward_spec (CompositeSpec): The original reward spec from the environment.\n",
        "\n",
        "        Returns:\n",
        "            CompositeSpec: The transformed reward spec with our custom reward definition.\n",
        "                The reward will have shape (B, 1) where B is the batch size.\n",
        "        \"\"\"\n",
        "        reward_spec[\"reward\"] = Unbounded(\n",
        "            shape=reward_spec.shape + (1,), dtype=torch.float32\n",
        "        )\n",
        "        return reward_spec\n",
        "\n",
        "\n",
        "# We append the reward transform to the environment.\n",
        "env = env.append_transform(RewardTransform())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Tool Execution Helper\n",
        "\n",
        "To make our interaction with tools more organized, we'll create a helper function\n",
        "that executes tool actions and displays the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Original execute_tool_action function - had wrong input format\n",
        "# def execute_tool_action(\n",
        "#     env: ChatEnv,\n",
        "#     current_state: TensorDict,\n",
        "#     action: str,\n",
        "#     verbose: bool = True,\n",
        "# ) -> tuple[TensorDict, TensorDict]:\n",
        "#     \"\"\"Execute a tool action and show the formatted interaction.\"\"\"\n",
        "#     s = current_state.set(\"text_response\", [action])\n",
        "#     s, s_ = env.step_and_maybe_reset(s)\n",
        "\n",
        "#     if verbose:\n",
        "#         print(\"\\nLLM Action:\")\n",
        "#         print(\"-----------\")\n",
        "#         print(action)\n",
        "#         print(\"\\nEnvironment Response:\")\n",
        "#         print(\"--------------------\")\n",
        "#         torchrl_logger.info(s_[\"history\"].apply_chat_template(tokenizer=env.tokenizer))\n",
        "\n",
        "#     return s, s_\n",
        "\n",
        "# Fixed execute_tool_action function - uses proper History format with simpler approach\n",
        "from torchrl.data.llm.history import History\n",
        "from torchrl.modules.llm.policies.common import ChatHistory\n",
        "\n",
        "def execute_tool_action(\n",
        "    env: ChatEnv,\n",
        "    current_state: TensorDict,\n",
        "    action: str,\n",
        "    verbose: bool = True,\n",
        ") -> tuple[TensorDict, TensorDict]:\n",
        "    \"\"\"Execute a tool action and show the formatted interaction.\"\"\"\n",
        "    \n",
        "    # Create a simple assistant response history that matches the expected structure\n",
        "    # Based on the ChatEnv design, we need to create a ChatHistory with \"full\" containing the response\n",
        "    assistant_history = History(\n",
        "        role=\"assistant\", \n",
        "        content=action, \n",
        "        is_complete=True\n",
        "    ).unsqueeze(0)  # Add batch dimension to match environment expectations\n",
        "    \n",
        "    # Create ChatHistory object with the assistant response as \"full\"\n",
        "    # This is what ChatEnv expects for input during step\n",
        "    chat_history = ChatHistory(full=assistant_history)\n",
        "    \n",
        "    # Create the input tensordict\n",
        "    s = current_state.clone().set(\"history\", chat_history)\n",
        "    \n",
        "    # Step the environment\n",
        "    s, s_ = env.step_and_maybe_reset(s)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nLLM Action:\")\n",
        "        print(\"-----------\")\n",
        "        print(action)\n",
        "        print(\"\\nEnvironment Response:\")\n",
        "        print(\"--------------------\")\n",
        "        if \"history\" in s_ and s_[\"history\"].prompt is not None:\n",
        "            torchrl_logger.info(s_[\"history\"].prompt.apply_chat_template(tokenizer=env.tokenizer))\n",
        "        else:\n",
        "            print(\"No history available in response\")\n",
        "\n",
        "    return s, s_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Starting the Interaction\n",
        "\n",
        "Let's begin by initializing the environment with a question and navigating\n",
        "to a search engine. Note that the tensordict used as input to the environment\n",
        "must share the same batch size as the environment. The text query is put in a list\n",
        "of length 1, such that it is compatible with the environment's batch size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll navigate to Google using the browser transform. The transform\n",
        "expects actions in a specific JSON format wrapped in tool tags.\n",
        "In practice, this action should be the output of our LLM which\n",
        "will write the response string in the `\"text_response\"` key.\n",
        "\n",
        "**Note:** The browser actions may fail in Jupyter notebooks due to event loop conflicts \n",
        "(\"This event loop is already running\"). This is a known limitation when mixing async \n",
        "operations with Jupyter's event loop. The tool calling framework and conversation \n",
        "management still work correctly - this demonstrates the core TorchRL LLM concepts \n",
        "even if the actual browser automation fails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LLM Action:\n",
            "-----------\n",
            "\n",
            "    Let me search for that:\n",
            "    <tool>browser\n",
            "    {\n",
            "        \"action\": \"navigate\",\n",
            "        \"url\": \"https://google.com\"\n",
            "    }\n",
            "    </tool><|im_end|>\n",
            "    \n",
            "\n",
            "Environment Response:\n",
            "--------------------\n",
            "\u001b[92m2025-09-16 14:55:32,573 [torchrl][INFO]\u001b[0m    ['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>assistant\\n\\n    Let me search for that:\\n    <tool>browser\\n    {\\n        \"action\": \"navigate\",\\n        \"url\": \"https://google.com\"\\n    }\\n    </tool><|im_end|>\\n    <|im_end|>\\n    <|im_start|>user\\n<tool_response>\\nTool browser failed:\\nTool execution failed: This event loop is already running\\n</tool_response><|im_end|>\\n<|im_start|>assistant\\n']\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# s, s_ = execute_tool_action(\n",
        "#     env,\n",
        "#     reset,\n",
        "#     \"\"\"\n",
        "#     Let me search for that:\n",
        "#     <tool>browser\n",
        "#     {\n",
        "#         \"action\": \"navigate\",\n",
        "#         \"url\": \"https://google.com\"\n",
        "#     }\n",
        "#     </tool><|im_end|>\n",
        "#     \"\"\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fix Event Loop (Advanced)\n",
        "\n",
        "If you want to use the real browser automation, you can fix the event loop issue with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reset = env.reset(\n",
        "    TensorDict(\n",
        "        # text=[\"What is the capital of France?\"],\n",
        "        query=[\"What is the capital of France?\"],\n",
        "        batch_size=(1,),\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Event loop patched! You can now use the real BrowserTransform.\n",
            "Note: You may need to restart the kernel if you encounter issues.\n"
          ]
        }
      ],
      "source": [
        "# Option 2: Fix the event loop issue for real browser automation\n",
        "# CAUTION: This modifies the global event loop and may have side effects\n",
        "\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "# Enable nested event loops (allows async code to run in Jupyter)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"✅ Event loop patched! You can now use the real BrowserTransform.\")\n",
        "print(\"Note: You may need to restart the kernel if you encounter issues.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Navigate to Google\n",
        "\n",
        "Now that we've fixed the event loop issue with `nest_asyncio.apply()`, we can properly navigate to Google. The previous navigation attempt failed due to the async conflict, so we need to retry it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m2025-09-16 16:14:47,428 [torchrl][INFO]\u001b[0m    Reached the website google.com\u001b[92m [END]\u001b[0m\n",
            "\n",
            "LLM Action:\n",
            "-----------\n",
            "\n",
            "    Let me navigate to Google to search for the capital of France:\n",
            "    <tool>browser\n",
            "    {\n",
            "        \"action\": \"navigate\",\n",
            "        \"url\": \"https://google.com\"\n",
            "    }\n",
            "    </tool>\n",
            "    \n",
            "\n",
            "Environment Response:\n",
            "--------------------\n",
            "\u001b[92m2025-09-16 16:14:47,432 [torchrl][INFO]\u001b[0m    ['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>assistant\\n\\n    Let me navigate to Google to search for the capital of France:\\n    <tool>browser\\n    {\\n        \"action\": \"navigate\",\\n        \"url\": \"https://google.com\"\\n    }\\n    </tool>\\n    <|im_end|>\\n    <|im_start|>user\\n<tool_response>\\nTool browser executed successfully:\\n{\\'success\\': True, \\'result\\': {\\'url\\': \\'https://www.google.com/\\', \\'status\\': 200}}\\n</tool_response><|im_end|>\\n<|im_start|>assistant\\n']\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Now that the event loop is fixed, let's navigate to Google.com\n",
        "# This is the step that failed before due to the async conflict\n",
        "# Use 'reset' since the previous s_ failed due to the async error\n",
        "s, s_ = execute_tool_action(\n",
        "    env,\n",
        "    reset,  # Use the reset state instead of s_ which doesn't exist\n",
        "    \"\"\"\n",
        "    Let me navigate to Google to search for the capital of France:\n",
        "    <tool>browser\n",
        "    {\n",
        "        \"action\": \"navigate\",\n",
        "        \"url\": \"https://google.com\"\n",
        "    }\n",
        "    </tool>\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Performing the Search\n",
        "\n",
        "With the browser open, we can now type our query and execute the search.\n",
        "First, we'll type the search query into Google's search box.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LLM Action:\n",
            "-----------\n",
            "\n",
            "    Let me type the search query:\n",
            "    <tool>browser\n",
            "    {\n",
            "        \"action\": \"type\",\n",
            "        \"selector\": \"[name='q']\",\n",
            "        \"text\": \"What is the capital of France?\"\n",
            "    }\n",
            "    </tool><|im_end|>\n",
            "    \n",
            "\n",
            "Environment Response:\n",
            "--------------------\n",
            "\u001b[92m2025-09-16 16:15:21,666 [torchrl][INFO]\u001b[0m    ['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>assistant\\n\\n    Let me type the search query:\\n    <tool>browser\\n    {\\n        \"action\": \"type\",\\n        \"selector\": \"[name=\\'q\\']\",\\n        \"text\": \"What is the capital of France?\"\\n    }\\n    </tool><|im_end|>\\n    <|im_end|>\\n    <|im_start|>user\\n<tool_response>\\nTool browser executed successfully:\\n{\\'success\\': True, \\'result\\': {\\'typed\\': \\'What is the capital of France?\\', \\'into\\': \"[name=\\'q\\']\"}}\\n</tool_response><|im_end|>\\n<|im_start|>assistant\\n']\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "s, s_ = execute_tool_action(\n",
        "    env,\n",
        "    s_,\n",
        "    \"\"\"\n",
        "    Let me type the search query:\n",
        "    <tool>browser\n",
        "    {\n",
        "        \"action\": \"type\",\n",
        "        \"selector\": \"[name='q']\",\n",
        "        \"text\": \"What is the capital of France?\"\n",
        "    }\n",
        "    </tool><|im_end|>\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll click the search button to execute the search. Note how we\n",
        "use CSS selectors to identify elements on the page.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LLM Action:\n",
            "-----------\n",
            "\n",
            "    Now let me click the search button:\n",
            "    <tool>browser\n",
            "    {\n",
            "        \"action\": \"click\",\n",
            "        \"selector\": \"[name='btnK']\"\n",
            "    }\n",
            "    </tool><|im_end|>\n",
            "    \n",
            "\n",
            "Environment Response:\n",
            "--------------------\n",
            "\u001b[92m2025-09-16 16:16:42,419 [torchrl][INFO]\u001b[0m    ['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>assistant\\n\\n    Now let me click the search button:\\n    <tool>browser\\n    {\\n        \"action\": \"click\",\\n        \"selector\": \"[name=\\'btnK\\']\"\\n    }\\n    </tool><|im_end|>\\n    <|im_end|>\\n    <|im_start|>user\\n<tool_response>\\nTool browser executed successfully:\\n{\\'success\\': True, \\'result\\': {\\'clicked\\': \"[name=\\'btnK\\']\"}}\\n</tool_response><|im_end|>\\n<|im_start|>assistant\\n']\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "s, s_ = execute_tool_action(\n",
        "    env,\n",
        "    s_,\n",
        "    \"\"\"\n",
        "    Now let me click the search button:\n",
        "    <tool>browser\n",
        "    {\n",
        "        \"action\": \"click\",\n",
        "        \"selector\": \"[name='btnK']\"\n",
        "    }\n",
        "    </tool><|im_end|>\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Extracting Results\n",
        "\n",
        "Finally, we'll extract the search results from the page. The browser transform\n",
        "can extract both text content and HTML from specified elements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m2025-09-16 16:16:54,108 [torchrl][INFO]\u001b[0m    Found the answer to the question: Paris\u001b[92m [END]\u001b[0m\n",
            "\n",
            "LLM Action:\n",
            "-----------\n",
            "\n",
            "    Let me extract the results:\n",
            "    <tool>browser\n",
            "    {\n",
            "        \"action\": \"extract\",\n",
            "        \"selector\": \"#search\",\n",
            "        \"extract_type\": \"text\"\n",
            "    }\n",
            "    </tool><|im_end|>\n",
            "    \n",
            "\n",
            "Environment Response:\n",
            "--------------------\n",
            "\u001b[92m2025-09-16 16:16:54,110 [torchrl][INFO]\u001b[0m    ['<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>assistant\\n\\n    Let me extract the results:\\n    <tool>browser\\n    {\\n        \"action\": \"extract\",\\n        \"selector\": \"#search\",\\n        \"extract_type\": \"text\"\\n    }\\n    </tool><|im_end|>\\n    <|im_end|>\\n    <|im_start|>user\\n<tool_response>\\nTool browser executed successfully:\\n{\\'success\\': True, \\'result\\': {\\'content\\': \\'People also askWhat are the two capitals of France?Brazzaville (1940–1943), with metropolitan France under Axis powers rule, Brazzaville was announced as the seat of the Free France government. Algiers (1943–1944), the city was made the seat of Free France, to be closer to the war in Europe. Paris (1945–present day).List of capitals of France - WikipediaWikipediahttps://en.wikipedia.org › wiki › List_of_capitals_of_Fr...Wikipediahttps://en.wikipedia.org › wiki › List_of_capitals_of_Fr...What is the real capital of France?ParisParis is the capital of France, the largest country of Europe with 550 000 km2 (65 millions inhabitants). Paris has 2.234 million inhabitants end 2011. She is the core of Ile de France region (12 million people).Paris facts: the capital of France in historyAdelphi Universityhttps://home.adelphi.edu › ...Adelphi Universityhttps://home.adelphi.edu › ...What was France\\\\\\'s capital before Paris?VersaillesHowever, Paris has not been the only capital in the country\\\\\\'s long existence. Other cities that served as the capital were: Troyes, Tours, Bourges, Versailles, Bordeaux, Clermont-Ferrand, Vichy, Brazzaville, Algiers and Bayeux.Apr 1, 2023What happened to France\\\\\\'s other capitals?The French History Podcasthttps://www.thefrenchhistorypodcast.com › what-happen...The French History Podcasthttps://www.thefrenchhistorypodcast.com › what-happen...What is the nickname of Paris?the City of LightsParis is known as the City of Love and as the City of Lights. However, Paris has more than just these two nicknames. Paris is also known as the Capital of Fashion, City of Art, City of Monuments, and City of Bridges.Oct 15, 2024Paris Nicknames: Is Paris the City of Lights or Love?Get Lost in Wanderlusthttps://www.getlostinwanderlust.com › paris-city-of-light...Get Lost in Wanderlusthttps://www.getlostinwanderlust.com › paris-city-of-light...Feedback(function(){var id=\\\\\\'fld_2g7JaK-xJ-W-0-kPtoqr4Ac_2\\\\\\';document.getElementById(id).setAttribute(\"lta\",Date.now());})();(function(){var eid=\\\\\\'fld_2g7JaK-xJ-W-0-kPtoqr4Ac_2\\\\\\';var a=Date.now(),b=document.getElementById(eid);if(b){var c=b.getAttribute(\"lta\");google.c.maft(c?Number(c):a,b)};})();.s6JM6d .eYa01b{width:148px}.s6JM6d .KtfA8c{width:204px}.s6JM6d .APo4S{margin-left:10px;margin-right:10px}.s6JM6d .THlyec{margin-left:-10px;margin-right:-10px;width:auto}.M8OgIe .hhv4Fb{margin-left:-38px;margin-right:-38px}.M8OgIe .JL6v7b{margin-left:38px;margin-right:38px}.M8OgIe .TRty9d{width:316px}@media (min-width:940px) and (max-width:1163.98px){.M8OgIe .TRty9d{width:260px}}@media (min-width:800px) and (max-width:939.98px){.M8OgIe .TRty9d{width:372px}}@media (min-width:550px) and (max-width:683.98px){.M8OgIe .TRty9d{width:calc(50% - 10px)}}@media (max-width:550px){.M8OgIe .TRty9d{width:100%}}.TQc1id .zLsiYe{margin-left:-21px;padding-left:0}.rXoM2c{color:var(--amnPwe)}.rXoM2c .niO4u{background-color:#f1f3f4}.QuU3Wb{margin-top:6px}.LwdV0e.OJeuxf .niO4u{width:36px;height:36px}.gUAcff.OJeuxf .niO4u{width:32px;height:32px}.NQYJvc.OJeuxf .niO4u{width:44px;height:44px}.OJeuxf .niO4u{margin:0 auto}.OJeuxf .kHtcsd{height:100%}.gJdC8e.gJdC8e.gJdC8e{margin:0}.OJeuxf .niO4u::before{width:48px;margin-left:-24px;left:50%}@media (max-width:799.98px){.TQc1id.vVVcqf .SjLxGf{display:none}}.s6JM6d .z4oRIf .mgAbYb{font-size:22px}.TQc1id .z4oRIf .mgAbYb{font-size:18px}.TQc1id .KFFQ0c{display:none}.srp .main{overflow-x:unset}@media (max-width:683.98px){.srp .YNk70c:not(.CvDJxb){column-gap:12px;grid-template-columns:minmax(4px,8px) repeat(12,calc(520px/12)) minmax(4px,8px)}}@media (min-width:800px) and (max-width:939.98px){.YNk70c .ufC5Cb{grid-column:2/span 8;}}@media (min-width:940px) and (max-width:1163.98px){.YNk70c .ufC5Cb{grid-column:2/span 10}}@media (max-width:1163.98px){.YNk70c .vVVcqf{display:block;grid-column:span 5/-2;max-width:100%}}.s6JM6d .z4oRIf .Jb0Zif.pEZBSb,.s6JM6d .z4oRIf.CeIyHb .XWkUDf,.s6JM6d .z4oRIf .CeIyHb .XWkUDf,.s6JM6d .z4oRIf.CeIyHb.XWkUDf,.s6JM6d .z4oRIf .CeIyHb.XWkUDf,.s6JM6d .z4oRIf .ss6qqb{margin-bottom:44px}.TQc1id .z4oRIf{max-width:100%}@media (min-width:800px){.s6JM6d .z4oRIf{height:0;margin:0;overflow:hidden;padding:0}}@media (max-width:799.98px){.TQc1id .z4oRIf{height:0;margin:0;overflow:hidden;padding:0 !important}}html:not(.zAoYTe) .kp-wholepage a{outline:0}.ss6qqb{border-bottom:1px solid var(--gS5jXb);line-height:1.58}#rhs .ss6qqb{border:1px solid #dadce0;border-radius:8px}#rhs .u7yw9{border:0;border-left:1px solid var(--gS5jXb);border-radius:0}.KsRP6{display:flex}.QpPSMb{align-items:center;display:flex;justify-content:space-between}.nwVKo{align-items:center;display:flex}.r2VLS{flex:0 0 22px;height:20px;padding:1px 0 1px 6px;width:22px}.nwVKo .r2VLS{margin-bottom:auto}.TQc1id .KsRP6{padding:0 0 16px 20px}.TQc1id .MDY31c,.z4oRIf .MDY31c{flex-grow:1}.BUX91{align-self:center}.s6JM6d .ss6qqb .KsRP6{margin:0 0 16px 0;padding:0}.a3glFf{color:#202124;cursor:pointer;display:flex;align-items:center}.ssJ7i{color:var(--YLNNHc);font-family:Google Sans,Arial,sans-serif;font-weight:500;word-break:break-word}.XqFnDf .ssJ7i,.M8OgIe .ssJ7i{font-size:28px;line-height:36px;}.XqFnDf .ssJ7i br,.M8OgIe .ssJ7i br{content:\\\\\\' \\\\\\';display:contents}.s6JM6d .ssJ7i{font-size:28px;line-height:36px;}.TQc1id .ssJ7i{font-size:28px;line-height:36px;}.iAIpCb{color:var(--bbQxAb);font-family:Arial,sans-serif;font-size:14px;line-height:20px;margin-top:4px;font-family:Arial,sans-serif;font-weight:400;line-height:18px}.xDKLO{}.ss6qqb .xDKLO{padding-top:0}(function(){var nsrp=true;var fsrp=false;var irrp=true;var escn=true;(function(){function b(a){return typeof a!==\"undefined\"&&a===!0}b(nsrp)&&document.getElementById(\"center_col\").classList.add(\"ZPOWwb\");b(fsrp)&&document.getElementById(\"rcnt\").classList.add(\"uW3HW\");function c(a,l){var e=document.getElementById(\"center_col\"),f=document.getElementById(\"rhs\");e&&f&&(e.classList.toggle(\"ZFGGlf\",a<=10),e.classList.toggle(\"B8S5Ve\",a<=8),f.classList.toggle(\"UE2fsd\",l<=5))}\\\\nif(document.getElementById(\"rhs\")&&b(escn)&&b(nsrp)){var d=window.matchMedia(\"(max-width: 799.98px)\"),g=window.matchMedia(\"(max-width: 939.98px)\"),h=window.matchMedia(\"(max-width: 1163.98px)\"),k=function(){d.matches&&irrp?c(12,0):g.matches?c(8,5):h.matches?c(10,5):c(12,7)};d.addEventListener(\"change\",k);g.addEventListener(\"change\",k);h.addEventListener(\"change\",k);k()};}).call(this);})();(function(){var id=\\\\\\'fld_2g7JaK-xJ-W-0-kPtoqr4Ac_3\\\\\\';document.getElementById(id).setAttribute(\"lta\",Date.now());})();(function(){var s=\\\\\\'data:image/jpeg;base64,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\\\\\\\\x3d\\\\\\';var ii=[\\\\\\'dimg_2g7JaK-xJ-W-0-kPtoqr4Ac_5\\\\\\'];_setImagesSrc(ii,s);})();(function(){var eid=\\\\\\'fld_2g7JaK-xJ-W-0-kPtoqr4Ac_3\\\\\\';var a=Date.now(),b=document.getElementById(eid);if(b){var c=b.getAttribute(\"lta\");google.c.maft(c?Number(c):a,b)};})();.vt6azd{margin:0px 0px 30px}.IiOSLb .rsGxI.Ww4FFb,.Ww4FFb{border-radius:0px;border-width:0}.IiOSLb .rsGxI.Ww4FFb,.Ww4FFb{background-color:var(--xhUGwc)}.IiOSLb .rsGxI.Ww4FFb,.Ww4FFb{box-shadow:none}.Ww4FFb .mnr-c:not(:empty),.mnr-c:not(:empty) .Ww4FFb{box-shadow:none;margin-bottom:0px}.BBwThe{font-weight:700}.MBeuO{font-family:Google Sans,Arial,sans-serif;font-size:20px;font-weight:400}.MBeuO{line-height:26px}.k1U36b{font-size:12px;font-family:Arial,sans-serif;font-weight:500;line-height:16px}.byrV5b{align-items:center;display:flex;flex-direction:row}.aAJbCe{display:-webkit-box;overflow:hidden;text-overflow:ellipsis;white-space:normal!important;-webkit-box-orient:vertical}@media (max-width:360px){.aAJbCe{word-break:break-word!important;-webkit-line-clamp:5!important}}.eJtrMc{padding-bottom:8px;padding-top:8px}.Bb1JKe{padding-bottom:8px}.EXH1Ce{position:relative}.CJHX3e{padding-bottom:12px;padding-top:12px}.XbQ34c{margin-left:auto}.UzglY{flex-grow:1;display:flex;flex-direction:column}.UzglY>*+*{margin-top:4px}.aKoISd{font-size:14px;line-height:18px;font-weight:500;font-family:Google Sans,Arial,sans-serif;color:var(--YLNNHc)}.aKoISd{font-weight:400}.OdBhM{padding-top:8px}.g1yMoc{width:100%;height:auto;display:block}.ESvzac{flex-shrink:0;flex-grow:0;overflow:hidden}.PND3bd{border-top-left-radius:16px;border-top-right-radius:16px}.Vgpgjf{border-top-left-radius:8px;border-top-right-radius:8px}.wYFOId{border-radius:8px}.ovklQ svg{transform:rotate(45deg)}.BToiNc{display:flex;flex-direction:column;justify-content:start}.pxiwBd .Ww4FFb{box-shadow:none}.tF2Cxc.asEBEc{margin-bottom:30px;}.N54PNb{position:relative}.kb0PBd{display:block;flex:0 0 auto}.A9Y9g{flex:1 1 100%;min-width:0}a:hover h3.LC20lb{text-decoration:underline}.LC20lb{display:inline-block;margin-bottom:3px;}.DKV0Md{padding-top:4px;padding-top:5px;}.DKV0Md,.Z3xoIb{margin-top:0;}.VjDLd .tjvcx,.IVvPP .tjvcx,.kno-kp .tjvcx,.VjDLd .kp-wholepage-osrp .tjvcx,.TQc1id .ss6qqb .tjvcx,.TQc1id .trNcde .tjvcx{display:inline-block;height:19px;overflow-y:hidden}.ojE3Fb{padding:0;max-width:calc(100% - 20px)}.ojE3Fb .q0vns{display:flex;padding:0;overflow:hidden;align-items:center;}.IVvPP .q0vns,.TQc1id .q0vns,.u7yw9 .q0vns,.z4oRIf .q0vns{align-items:center;display:inline-flex}.GvPZzd{font-size:12px;line-height:18px;max-width:max-content;overflow-x:hidden;text-overflow:ellipsis;width:100%}.dTxz9{padding-right:38px}.DDKf1c{margin-right:12px;}.UnOTSe img{border:1px solid var(--mXZkqc);background-color:var(--XKMDxc);border-radius:50%;}.Vwoesf:not(.oRVWZ){display:inline-block}.Vwoesf{vertical-align:middle}.XNo5Ab.XNo5Ab{display:block;}.Jj3Uob{color:var(--TMYS9);}.VuuXrf{color:#202124;font-size:14px;display:block;line-height:20px;white-space:nowrap;overflow-x:hidden;text-overflow:ellipsis;width:auto;}.CA5RN{overflow:hidden}.ob9lvb{color:#4d5156}.ylgVCe{color:#4d5156}.B6fmyf{max-height:0;position:relative;top:19px;visibility:hidden}.B6fmyf.Mg1HEd{height:auto}.csDOgf{display:inline;visibility:visible}.csDOgf.BCF2pd.ezY6nb,.csDOgf.L48a4c{height:18px}.csDOgf{margin-left:8px;position:relative}.csDOgf.L48a4c{margin-top:16px}.csDOgf .MJ8UF{padding-left:0;}.p4wth{font-family:Arial,sans-serif;font-size:14px;font-weight:400;line-height:22px;color:var(--bbQxAb);}.p4wth b{color:#767676}.VwiC3b{word-break:break-word}.Hdw6tb{display:-webkit-box;-webkit-box-orient:vertical;overflow:hidden}sup,sub{vertical-align:baseline;position:relative;top:-0.4em}sub{top:0.4em}.ULSxyf{margin-bottom:44px}.adDDi.PJI6ge{padding-bottom:0}g-inner-card.T19leb{border-radius:12px}.T19leb{display:inline-block;width:148px}.T19leb:not(:first-child){margin-left:20px}.AZJdrc,.Svi2Id{position:relative}.AZJdrc.zGXzeb,.AZJdrc.zGXzeb .Svi2Id{display:table}.AZJdrc.aQElvf,.AZJdrc.aQElvf .Svi2Id{width:100%;height:100%}.kCyj6d{overflow:hidden;isolation:isolate}.LIna9b,.AZJdrc .kSFuOd,.AZJdrc.aQElvf .rIRoqf{position:absolute;top:0;left:0;bottom:0;right:0}.LIna9b{overflow:hidden;border-radius:inherit}.FNYvEb{border-radius:12px}.JceRhc{border-radius:16px}.hXR9Df{position:absolute;bottom:0;left:0;right:0;top:0;background:linear-gradient(180deg,rgba(0,0,0,0) 55%,rgba(0,0,0,0.5) 80%,rgba(0,0,0,0.7) 100%)}.p44l0{bottom:0;padding:8px;position:absolute;cursor:pointer}.dbhQEb{display:-webkit-box;box-sizing:border-box;color:#fff;font-family:Arial,sans-serif;font-size:16px;line-height:20px;-webkit-line-clamp:2;-webkit-box-orient:vertical;hyphens:auto}.yTYr4d{overflow:hidden;text-overflow:ellipsis;white-space:normal;word-break:break-word}.InnpM{display:flex;width:100%;color:rgba(255,255,255,0.8);font-size:12px;line-height:16px;margin-top:6px}.IlXDce{-webkit-line-clamp:1;-webkit-box-orient:vertical;display:-webkit-box}.qtekab{flex-shrink:0;margin-right:4px}.WVV5ke{display:contents}.hXY9cf{cursor:pointer;outline-offset:1px;z-index:1}.rkqHyd{margin:6px 8px}.rkqHyd{margin:8px}.rkqHyd.JceRhc{margin:12px}.Vtx8Xc{position:absolute;top:0;right:0}.jrwKTb{background-color:var(--gVUKcd);border-radius:50%;color:var(--EoKObe);width:14px;height:14px;line-height:14px;padding:3px}.jrwKTb span{display:block}.jRKCUd::before{bottom:12px;content:\\\\\\'\\\\\\';left:16px;position:absolute;right:16px;top:-4px}a.jRKCUd:hover{text-decoration:none}.H9lube{background-color:var(--XKMDxc);border:1px solid var(--mXZkqc);border-radius:50%;display:inline-flex;justify-content:center;align-items:center;height:26px;width:26px;margin-right:12px;flex-shrink:0;vertical-align:middle;}.fJOpI.H9lube{border:1px solid var(--TSWZIb);background-color:var(--TSWZIb);}.eqA2re.NjwKYd{margin-right:0}.PmEWq{position:relative;width:100%}.xe8e1b{line-height:20px}.iHxmLe{display:flex;line-height:1.58;max-width:48em;margin-top:4px}.gY2b2c{border-radius:8px;height:fit-content;justify-content:center;margin-right:20px;margin-top:4px;position:relative;width:fit-content;}.fzUZNc{flex-grow:1}.Px5SRc{padding-top:8px}.Px5SRc:empty{display:none}.Px5SRc div{display:inline-block;margin-right:16px}.Ylm8Fc{left:50%;line-height:0;position:absolute;top:50%;transform:translate(-50%,-50%)}.Ylm8Fc.YmeD8e{margin-top:-6px}.MfcGr{fill:var(--gVUKcd)}.Nci3Ge{fill:var(--EoKObe)}.c8rnLc{position:absolute;bottom:0;left:0}.zCaigb{border-radius:10px;padding-block:2px;padding-inline:8px}.flgn0c{background-color:var(--gVUKcd);color:var(--EoKObe);fill:var(--EoKObe)}.ITZIwc{-webkit-box-orient:vertical;display:-webkit-box;-webkit-line-clamp:2;overflow:hidden;word-break:break-word}.eFM0qc{display:inline-flex;padding-bottom:2px;padding-top:1px;padding-left:2px;visibility:visible;align-items:center}.LAWljd{padding:0 4px 0 4px}.eFM0qc.BCF2pd{align-items:center;background:var(--xhUGwc);display:flex;padding:0;margin-left:4px}.dEEN8c{font-size:12px;line-height:18px}.RTaUke{display:none;opacity:0}.oIk2Cb{margin:0}.oqQXff{height:16px}.FalWJb{background:var(--xhUGwc)}.y6Uyqe{padding:6px 0 0 0;width:100%;}.IPpbe{margin-top:12px}.TQc1id .IPpbe{margin-top:16px}.BHRICd{width:92px}.TQc1id .BHRICd{width:84px}.XNfAUb{display:block;position:relative;}.RyIFgf{display:block;overflow-x:auto;overflow-y:clip;position:relative;transform:translate3d(0,0,0);transform:translate3d(0,0,0);}.RyIFgf::-webkit-scrollbar{display:none}.HG5ZQb{display:flex}.XRVJtc.bnmjfe{display:flex}.bnmjfe>.VqeGe,.bnmjfe>.VqeGe>a{display:flex}.XRVJtc.aKByQb{margin-right:20px}.TQc1id .XRVJtc.aKByQb{margin-right:12px}.XRVJtc.aKByQb:not(.q2ch8c):last-of-type{margin-right:0px}.p7bv{display:flex;flex-direction:column;flex:auto}.EXH1Ce{position:relative}.IF221e{display:-webkit-flex;flex-direction:column;flex:auto}.T3Fozb{text-decoration:none}.T3Fozb:hover{text-decoration:none}.c30Ztd:hover~.T3Fozb .CvgGZ{text-decoration:underline}.c30Ztd:hover~.CvgGZ{text-decoration:underline}.qrtwm:focus-visible{outline:2px solid var(--Pa8Wlb);border-radius:8px;box-sizing:border-box;outline-offset:-2px}.c30Ztd{position:absolute;z-index:1;top:0;left:0;height:100%;width:100%}.Yt787{word-break:break-word;}.pQXcHc{cursor:default;opacity:0;visibility:hidden}.EQOGhe{user-select:none}.EIaa9b{display:flex;column-gap:16px;flex-wrap:wrap}.AJLUJb{display:flex;flex:1;flex-direction:column;min-width:233px}.b2Rnsc{display:flex;height:52px;margin:4px 0 4px 0}.vIifob{align-items:center;background:#f7f8f9;border-radius:8px;justify-content:center;}.b2Rnsc:hover{text-decoration:underline}.b2Rnsc:hover a{text-decoration-color:#1f1f1f}.qR29te{display:flex;flex-direction:column;flex-grow:1;min-width:0}.B2VR9{display:flex;align-items:center}.ggLgoc{display:block}.wyccme{min-width:0;display:flex;flex-direction:column;justify-content:center;flex-grow:1;overflow:hidden}.ngTNl{text-decoration:none}.ngTNl:hover{text-decoration:none}.ngTNl:focus-visible{outline-color:var(--Pa8Wlb);outline-offset:2px;outline-width:2px}.oatEtb{align-items:center;display:flex;gap:12px;justify-content:space-between;margin-left:16px;padding-right:9px}.mtv5bd{display:flex;height:100%;flex-direction:column;max-width:100%}.dg6jd{color:#1f1f1f;-webkit-line-clamp:2;overflow-wrap:break-word;font-family:Google Sans,Arial,sans-serif;font-size:16px;}.dg6jd span{font-weight:700;}.DxHbyd{background-color:transparent;align-items:center;border-radius:50%;display:flex;height:20px;justify-content:center;margin-right:8px;padding-left:9px;padding-right:7px;width:20px}.yiwlZe{color:#747878;display:block}.AaVjTc a:link{display:block;color:#4285f4;font-weight:normal}.AaVjTc td{padding:0;text-align:center}.YyVfkd{color:var(--YLNNHc);font-weight:normal;overflow:hidden}.AaVjTc{margin:30px auto 30px}.UUoiQc,.LLNLxf{max-width:calc(100vw - 32px - 335px + 55px);min-width:84px;overflow:hidden}@media (max-width:484px){.mYW5bd .NKTSme:nth-child(11),.RcEbob .NKTSme:nth-child(2){display:none}}@media (max-width:464px){.mYW5bd .NKTSme:nth-child(10),.RcEbob .NKTSme:nth-child(3){display:none}}@media (max-width:359px){.mYW5bd .NKTSme:nth-child(9),.RcEbob .NKTSme:nth-child(4){display:none}}@media (max-width:339px){.mYW5bd .NKTSme:nth-child(8),.RcEbob .NKTSme:nth-child(5){display:none}}.SJajHc{background:url(/images/nav_logo321.webp) no-repeat;background-size:167px;overflow:hidden;background-position:0 0;height:40px;display:block}.NVbCr{cursor:pointer}.oeN89d{clear:both}.LLNLxf .oeN89d{float:right}.oeN89d{text-wrap:nowrap}ParisWikipediahttps://en.wikipedia.org › wiki › ParisWikipediahttps://en.wikipedia.org › wiki › ParisParis is the capital and largest city of France, with an estimated population of 2,048,472 in January 2025 in an area of more than 105 km2 (41 sq mi).Paris, France - Intercultural Cities ProgrammeThe Council of Europehttps://www.coe.int › ... › MembersThe Council of Europehttps://www.coe.int › ... › MembersParis is the capital and most populous city of France. Situated on the Seine River, in the north of the country, it is in the centre of the Île-de-France\\\\xa0...Short videosiFly Tourism on Instagram: \"Paris, the capital of France, is ...Instagram\\\\xa0·\\\\xa0iflytours_What\\\\\\'s the Capital of France? Find Out with Fun Facts About ...YouTube\\\\xa0·\\\\xa0AbelaAbelaYouTube·Jan 10, 2025What\\\\\\'s the Capital of France? Find Out with Fun Facts About ...YouTube·Abela·Jan 10, 2025YouTubeWhat is the capital of France?YouTube\\\\xa0·\\\\xa0Smart Study for CareerSmart Study for CareerYouTube·May 19, 2025What is the capital of France?YouTube·Smart Study for Career·May 19, 2025YouTubeWhat is the CAPITAL of France 🇫🇷 | OSHUFacebook\\\\xa0·\\\\xa0OSHUWhat\\\\\\'s the capital of France? : r/funnyvideosReddit\\\\xa0·\\\\xa0r/funnyvideosDiscover the Capital of France: Is It Really Paris?TikTok\\\\xa0·\\\\xa0holdendavenportWhat is the Capital of France? | GK Quiz Shorts #gk #capital ...YouTube\\\\xa0·\\\\xa0Smart Study for CareerSmart Study for CareerYouTube·Sep 5, 2025What is the Capital of France? | GK Quiz Shorts #gk #capital ...YouTube·Smart Study for Career·Sep 5, 2025YouTubeWhat is the capital in France?\\\\u2063 .\\\\u2063 Watch your favorite social ...Facebook\\\\xa0·\\\\xa0Pulse NigeriaWhat\\\\\\'s the Capital of France? (Easy Trivia!)TikTok\\\\xa0·\\\\xa0itsjustethanromanWhat is the Capital of France?YouTube\\\\xa0·\\\\xa0Quiz HavenQuiz HavenYouTube·May 5, 2025What is the Capital of France?YouTube·Quiz Haven·May 5, 2025YouTube(function(){\\\\n(this||self).cVrhhd=function(b,e,q,a,h,k){if((b=document.getElementById(b))&&(b.offsetWidth!==0||b.offsetHeight!==0)){var l=b.querySelector(\"div\"),m=l.querySelector(\"div\"),c=0,g=Math.max(l.scrollWidth-l.offsetWidth,0);if(e>0){var n=m.children;c=n[e].offsetLeft-n[0].offsetLeft;if(a){for(var p=c=0;p<e;++p)c+=n[p].offsetWidth;c=Math.min(g,c)}}c+=q;e=Math.min(a?g-c:c,g);l.scrollLeft=a&&k?c:a&&h?-c:e;var d=b.getElementsByTagName(\"g-left-button\")[0],f=b.getElementsByTagName(\"g-right-button\")[0];d&&f&&(h=\\\\nRegExp(\"\\\\\\\\\\\\\\\\btHT0l\\\\\\\\\\\\\\\\b\"),k=RegExp(\"\\\\\\\\\\\\\\\\bpQXcHc\\\\\\\\\\\\\\\\b\"),d.className=d.className.replace(h,\"\"),f.className=f.className.replace(h,\"\"),d.className=e===0?\"pQXcHc \"+d.className:d.className.replace(k,\"\"),f.className=e===g?\"pQXcHc \"+f.className:f.className.replace(k,\"\"),d.className.indexOf(\"SL0Gp\")>=0&&e===0&&e===g&&(m.style.paddingLeft=\"0px\",m.style.paddingRight=\"0px\",d.style.display=\"none\",f.style.display=\"none\",b.style.paddingLeft=a?\"0px\":\"48px\",b.style.paddingRight=a?\"48px\":\"0px\",b.style.textAlign=a?\"left\":\"right\",(a=document.getElementById(\"fade_forward\"))&&(a.style.display=\"none\"),(a=document.getElementById(\"fade_reverse\"))&&(a.style.display=\"none\")),setTimeout(function(){d.className+=\" tHT0l\";f.className+=\" tHT0l\"},50))}};}).call(this);(function(){var id=\\\\\\'_2g7JaK-xJ-W-0-kPtoqr4Ac_125\\\\\\';var index=0;var offset=0;var is_rtl=false;var is_gecko=false;var is_edge=false;var init=\\\\\\'cVrhhd\\\\\\';window[init](id,index,offset,is_rtl,is_gecko,is_edge);})();More short videosList of capitals of FranceWikipediahttps://en.wikipedia.org › wiki › List_of_capitals_of_Fr...Wikipediahttps://en.wikipedia.org › wiki › List_of_capitals_of_Fr...The capital of France has been Paris since its liberation in 1944.Paris facts: the capital of France in historyAdelphi Universityhttps://home.adelphi.edu › ...Adelphi Universityhttps://home.adelphi.edu › ...Paris is the capital of France, the largest country of Europe with 550 000 km2 (65 millions inhabitants). Paris has 2.234 million inhabitants end 2011.Paris | Definition, Map, Population, Facts, & HistoryBritannicahttps://www.britannica.com › ... › Cities & Towns P-SBritannicahttps://www.britannica.com › ... › Cities & Towns P-SParis, city and capital of France, located along the Seine River, in the north-central part of the country. Paris is one of the world\\\\\\'s most important and\\\\xa0...Discover the city of Paris | Paris the capital city of Francecia-france.comhttps://www.cia-france.com › Paris › City of Pariscia-france.comhttps://www.cia-france.com › Paris › City of ParisParis is the city of romance par excellence, the fashion capital and the best example of French art de vivre. Exploring Paris is an essential rite of passage\\\\xa0...Paris 4K - Paris Capital Of France In 4K |YouTube\\\\xa0·\\\\xa04k Explore World55.8K+ views  ·  9 months agoYouTube\\\\xa0·\\\\xa04k Explore World55.8K+ views  ·  9 months ago4:01Paris Capital City Of France In 4K Ultra HD Video | Paris, France Capital And Largest City | Paris Is A Major European City And A Global\\\\xa0...4k Explore World YouTube·Dec 8, 2024Paris 4K - Paris Capital Of France In 4K |YouTube·4k Explore World ·Dec 8, 2024YouTubecapital of franceの意味・使い方・読み方 | Weblio英和辞書英和辞典https://ejje.weblio.jp › content › ca...英和辞典https://ejje.weblio.jp › content › ca... · Translate this pageParis is the capital of France. パリはフランスの首都だ。 - Tatoeba例文. 例文帳に追加. the capital of France, a city called ParisiFly Tourism on Instagram: \"Paris, the capital of France, is ...Instagram\\\\xa0·\\\\xa0iflytours_8 likes  ·  8 months agoInstagram\\\\xa0·\\\\xa0iflytours_8 likes  ·  8 months ago0:25Paris, the capital of France, is often referred to as the \"City of Light\" and is renowned for its art, culture, and history. It is home to\\\\xa0...\\', \\'type\\': \\'text\\'}}\\n</tool_response><|im_end|>\\n<|im_start|>assistant\\n']\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "s, s_ = execute_tool_action(\n",
        "    env,\n",
        "    s_,\n",
        "    \"\"\"\n",
        "    Let me extract the results:\n",
        "    <tool>browser\n",
        "    {\n",
        "        \"action\": \"extract\",\n",
        "        \"selector\": \"#search\",\n",
        "        \"extract_type\": \"text\"\n",
        "    }\n",
        "    </tool><|im_end|>\n",
        "    \"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's close the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This tutorial demonstrates how to build and compose LLM environments with tool capabilities\n",
        "in TorchRL. We've shown how to create a complete environment that can execute tools,\n",
        "format responses, and handle interactions between the LLM and external tools.\n",
        "\n",
        "The key concepts are:\n",
        "\n",
        "1. **Environment Composition**: Understanding TorchRL's LLM environment composition\n",
        "2. **Tool Integration**: Creating and appending tool transforms\n",
        "3. **Conversation Management**: Formatting tool responses and LLM interactions using History and ChatHistory\n",
        "4. **State Management**: Handling tool execution and state management\n",
        "5. **Wrapper Integration**: Integrating with LLM wrappers (vLLM, Transformers)\n",
        "\n",
        "### Troubleshooting Browser Issues\n",
        "\n",
        "If you encounter \"This event loop is already running\" errors:\n",
        "\n",
        "1. **Use the Mock Transform**: Replace BrowserTransform with MockBrowserTransform for educational purposes\n",
        "2. **Apply nest_asyncio**: Use `nest_asyncio.apply()` to fix event loop conflicts  \n",
        "3. **Run in Terminal**: Execute the script outside Jupyter for full browser automation\n",
        "\n",
        "The core TorchRL LLM framework concepts work correctly regardless of browser automation issues.\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Explore other tool transforms (file operations, API calls, etc.)\n",
        "- Integrate with actual LLM inference using vLLMWrapper or TransformersWrapper\n",
        "- Build custom reward functions for reinforcement learning scenarios\n",
        "- Create multi-turn conversations with complex tool interactions\n",
        "\n",
        "See the `ref_llms` tutorial for more information on how to build tool-enabled\n",
        "environments with TorchRL."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dbcls",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
